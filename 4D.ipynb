{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4D.ipynb",
      "provenance": [],
      "mount_file_id": "1M6TncjSHTE514ReBiJZg9-3aB0fWM9lq",
      "authorship_tag": "ABX9TyPJqhxyG6e+Fc4Xd5G/Ffxb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ADMoreau/High_dimensional_cellular_automata/blob/main/4D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38m336jZ44RI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ec24de8-006b-452d-df7d-e48268d4be87"
      },
      "source": [
        "!pip install -q plotly==4.9\n",
        "!pip install -q kaleido\n",
        "\n",
        "import plotly.io as pio\n",
        "pio.kaleido.scope.defaul_height = \"300\"\n",
        "pio.kaleido.scope.defaul_width = \"300\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 12.9MB 12.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 79.9MB 61kB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ao17okMYyM5"
      },
      "source": [
        "import numpy as np\n",
        "import sys \n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pylab as pl\n",
        "import json \n",
        "from IPython.display import Image, HTML, clear_output\n",
        "import plotly.graph_objects as go\n",
        "from math import sqrt    \n",
        "import itertools"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QThvSH0MyQQv"
      },
      "source": [
        "def distance_dimension(xyz0 = [], xyz1 = []):\n",
        "    delta_OX = pow(xyz0[0] - xyz1[0], 2)\n",
        "    delta_OY = pow(xyz0[1] - xyz1[1], 2)\n",
        "    delta_OZ = pow(xyz0[2] - xyz1[2], 2)\n",
        "    return sqrt(delta_OX+delta_OY+delta_OZ)    \n",
        "\n",
        "def voxels_figure(figure = 'sphere', position = [0,0,0], radius = 1):\n",
        "    xmin, xmax = position[0]-size,  position[0]+size+1\n",
        "    ymin, ymax = position[1]-size,  position[1]+size+1\n",
        "    zmin, zmax = position[2]-size,  position[2]+size+1\n",
        "\n",
        "    voxels = []\n",
        "\n",
        "    if figure == 'cube':\n",
        "        for local_z, world_z in zip(range(zmax-zmin), range(zmin, zmax)):\n",
        "            for local_y, world_y in zip(range(ymax-ymin), range(ymin, ymax)):\n",
        "                for local_x, world_x in zip(range(xmax-xmin), range(xmin, xmax)):\n",
        "                    voxels.append([world_x,world_y,world_z])\n",
        "\n",
        "    elif figure == 'sphere':\n",
        "        for local_z, world_z in zip(range(zmax-zmin), range(zmin, zmax)):\n",
        "            for local_y, world_y in zip(range(ymax-ymin), range(ymin, ymax)):\n",
        "                for local_x, world_x in zip(range(xmax-xmin), range(xmin, xmax)):\n",
        "                    radius = distance_dimension(xyz0 = [world_x, world_y,world_z], xyz1 = position)\n",
        "                    if  radius < size:\n",
        "                        voxels.append([world_x,world_y,world_z])\n",
        "    return voxels\n",
        "\n",
        "#get all voxels in a sphere with center 3, 2, 2 and a radius of 2\n",
        "size = 7\n",
        "voxels = voxels_figure(figure = 'sphere', position = [3, 2, 2], radius = 2) #working 4d"
      ],
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45TDzW6e2ekF"
      },
      "source": [
        "#Draw these voxels in a cube of zeros, here we are selecting only every third voxel as this improves performance \n",
        "sphere = np.zeros(shape=(size, size, size))\n",
        "for i in range(0, len(voxels), 3):\n",
        "  temp = voxels[i]\n",
        "  sphere[temp[0], temp[1], temp[2]] = np.random.random_sample()"
      ],
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z_JoRHW3x3f"
      },
      "source": [
        "#make the voxels grow linearly and limit values between 1 and 0 to create the temporal sequence \n",
        "growth = np.ones(shape=(len(voxels)))\n",
        "seq = np.zeros(shape=(size, size, size, size))\n",
        "seq[0, ...] = sphere.copy()\n",
        "for time in range(1, 5):\n",
        "  #temp_sphere = sphere.copy()\n",
        "  for i in range(0, len(voxels), 3):\n",
        "    temp_voxel = voxels[i]\n",
        "    if sphere[temp_voxel[0], temp_voxel[1], temp_voxel[2]] >= 1.0: growth[i] = -1.0\n",
        "    if sphere[temp_voxel[0], temp_voxel[1], temp_voxel[2]] <= 0.0: growth[i] = 1.0\n",
        "    sphere[temp_voxel[0], temp_voxel[1], temp_voxel[2]] += .1 * growth[i]\n",
        "  seq[time, ...] = sphere.copy()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8fzlisC03g8"
      },
      "source": [
        "#simple visualizion using plotly\n",
        "X, Y, Z = np.mgrid[0:size:1, 0:size:1, 0:size:1]\n",
        "fig = go.Figure(data=go.Volume(\n",
        "    x=X.flatten(),\n",
        "    y=Y.flatten(),\n",
        "    z=Z.flatten(),\n",
        "    value=seq[0, ...].flatten(),\n",
        "    isomin=0.1,\n",
        "    isomax=1.0,\n",
        "    opacity=1.0, # needs to be small to see through all surfaces\n",
        "    surface_count=600, # needs to be a large number for good volume rendering\n",
        "    ))\n",
        "#fig.write_image(\"temporal_original_first.png\")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laIEvBab56pb"
      },
      "source": [
        "fig = go.Figure(data=go.Volume(\n",
        "    x=X.flatten(),\n",
        "    y=Y.flatten(),\n",
        "    z=Z.flatten(),\n",
        "    value=seq[-1, ...].flatten(),\n",
        "    isomin=0.1,\n",
        "    isomax=1.0,\n",
        "    opacity=1.0, # needs to be small to see through all surfaces\n",
        "    surface_count=600, # needs to be a large number for good volume rendering\n",
        "    ))\n",
        "#fig.write_image(\"temporal_original_last.png\")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIvNw0Jg1BRu"
      },
      "source": [
        "#create the alpha channel\n",
        "alpha = seq > 0.0"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u31OcX5k8tuO"
      },
      "source": [
        "seq = np.stack((seq, alpha), axis = -1)"
      ],
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI3tYNQ6ZfbN"
      },
      "source": [
        "##@title Cellular Automata Parameters\n",
        "CHANNEL_N = 16       # Number of CA state channels\n",
        "BATCH_SIZE = 64\n",
        "CELL_FIRE_RATE = 0.5\n",
        "POOL_SIZE = 1024"
      ],
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMoPC05FmmsQ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "@tf.function\n",
        "def maxpool4d(data):\n",
        "    # input, kernel, and output sizes\n",
        "    (b, wi, zi, yi, xi, c) = data.shape.as_list()\n",
        "    (wk, zk, yk, xk, ik, ok) = (1, 3, 3, 3, 3, 1)\n",
        "\n",
        "    # output size and tensor\n",
        "    wo = wi - wk + 1\n",
        "    results = [ None ]*wo\n",
        "\n",
        "    # convolve each kernel frame i with each input frame j\n",
        "    for i in range(wk):\n",
        "        for j in range(wi):\n",
        "        \n",
        "          # add results to this output frame\n",
        "          out_frame = j - (i - wk//2) - (wi - wo)//2\n",
        "          if out_frame < 0 or out_frame >= wo:\n",
        "              continue\n",
        "\n",
        "          # convolve input frame j with kernel frame i\n",
        "          max = tf.nn.max_pool3d(tf.reshape(data[:,:,j,:,:], (b, zi, yi, xi, c)),\n",
        "                                 3, [1, 1, 1, 1, 1], 'SAME')\n",
        "\n",
        "          if results[out_frame] is None:\n",
        "              results[out_frame] = max\n",
        "          else:\n",
        "              results[out_frame] += max\n",
        "\n",
        "    return tf.stack(results, axis=2)\n",
        "\n",
        "#from https://dev.to/meseta/advent-of-code-day-17-using-more-tensorflow-and-4d-convolution-in-python-3ifd\n",
        "\n",
        "@tf.function\n",
        "def conv4d(data, conv_filt):\n",
        "    # input, kernel, and output sizes\n",
        "    (b, wi, zi, yi, xi, c) = data.shape.as_list()\n",
        "    (wk, zk, yk, xk, ik, ok) = conv_filt.shape.as_list()\n",
        "\n",
        "    # output size and tensor\n",
        "    wo = wi - wk + 1\n",
        "    results = [ None ]*wo\n",
        "\n",
        "    # convolve each kernel frame i with each input frame j\n",
        "    for i in range(wk):\n",
        "        for j in range(wi):\n",
        "        \n",
        "          # add results to this output frame\n",
        "          out_frame = j - (i - wk//2) - (wi - wo)//2\n",
        "          if out_frame < 0 or out_frame >= wo:\n",
        "              continue\n",
        "\n",
        "          # convolve input frame j with kernel frame i\n",
        "          frame_conv3d = tf.nn.convolution(tf.reshape(data[:,:,j,:,:], (b, zi, yi, xi, c)), conv_filt[:,:,:,i])\n",
        "\n",
        "          if results[out_frame] is None:\n",
        "              results[out_frame] = frame_conv3d\n",
        "          else:\n",
        "              results[out_frame] += frame_conv3d\n",
        "\n",
        "    return tf.stack(results, axis=2)\n",
        "\n",
        "class Conv4D(keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Adaptive convolutional layer for any necessary dimension\n",
        "    From : https://stackoverflow.com/questions/60782034/how-to-create-a-keras-layer-to-do-a-4d-convolutions-conv4d\n",
        "    \"\"\"\n",
        "    def __init__(self, filters, kernel_size, padding='VALID', kernel_initializer='glorot_uniform', activation=None, bias=True, **kwargs):\n",
        "      self.filters = filters\n",
        "      self.kernel_size = kernel_size #must be a tuple!!!!\n",
        "      self.padding=padding\n",
        "      self.is_bias = bias\n",
        "      self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
        "      self.activation = keras.activations.get(activation)\n",
        "\n",
        "      super(Conv4D, self).__init__(**kwargs)\n",
        "\n",
        "    #using channels last!!!\n",
        "    def build(self, input_shape):\n",
        "      spatialDims = len(self.kernel_size)\n",
        "      allDims = len(input_shape)\n",
        "      assert allDims == spatialDims + 2 #spatial dimensions + batch size + channels\n",
        "\n",
        "      kernelShape = self.kernel_size + (input_shape[-1], self.filters)\n",
        "          #(spatial1, spatial2,...., spatialN, input_channels, output_channels)\n",
        "\n",
        "      biasShape = tuple(1 for _ in range(allDims-1)) + (self.filters,)\n",
        "\n",
        "\n",
        "      self.kernel = self.add_weight(name='kernel', \n",
        "                                    shape=kernelShape,\n",
        "                                    initializer='uniform',\n",
        "                                    trainable=True)\n",
        "      if self.is_bias == True:\n",
        "        self.bias = self.add_weight(name='bias', \n",
        "                                    shape = biasShape, \n",
        "                                    initializer='zeros',\n",
        "                                    trainable=True)\n",
        "      self.built = True\n",
        "\n",
        "    def call(self, inputs):\n",
        "      if self.kernel_size == (3, 3, 3, 3):\n",
        "        inputs = tf.pad(inputs, [(0, 0), (1, 1), (1, 1), (1, 1), (1, 1), (0, 0)])\n",
        "      if self.kernel_size == (5, 5, 5, 5):\n",
        "        inputs = tf.pad(inputs, [(0, 0), (2, 2), (2, 2), (2, 2), (2, 2), (0, 0)])\n",
        "      results = conv4d(inputs, self.kernel)\n",
        "      if self.is_bias == True:\n",
        "        results += self.bias\n",
        "      if self.activation is not None:\n",
        "        return self.activation(results)\n",
        "      return results"
      ],
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltqaHk6yB5R4"
      },
      "source": [
        "from tensorflow.keras.layers import Conv3D\n",
        "\n",
        "def get_living_mask(x):\n",
        "  alpha = x[:, :, :, :, 1:2]\n",
        "  return tf.nn.max_pool3d(alpha, 3, [1, 1, 1, 1, 1], 'SAME') > 0.1\n",
        "\n",
        "def make_seed(size, n=1):\n",
        "  x = np.zeros([n, size, size, CHANNEL_N], np.float32)\n",
        "  x[:, size//2, size//2, 3:] = 1.0\n",
        "  return x\n",
        "\n",
        "class CAModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, channel_n=CHANNEL_N, fire_rate=CELL_FIRE_RATE, dim=4, layers=128):\n",
        "    super().__init__()\n",
        "    self.channel_n = channel_n\n",
        "    self.fire_rate = fire_rate\n",
        "    self.dim = dim\n",
        "\n",
        "    if self.dim == 3:\n",
        "      self.dmodel = tf.keras.Sequential([\n",
        "            Conv3D(layers, 1, activation=tf.nn.relu, padding='SAME', kernel_initializer='normal'),\n",
        "            Conv3D(self.channel_n, 1, activation=None,\n",
        "                kernel_initializer=tf.zeros_initializer),\n",
        "      ])\n",
        "\n",
        "      self(tf.zeros([1, 3, 3, 3, channel_n]))  # dummy call to build the model\n",
        "\n",
        "    if self.dim == 4:\n",
        "\n",
        "      #create the 4D convolutional layers for the sobel operators and identify mat\n",
        "      self.identity_conv = Conv4D(1, (3,3,3,3), bias=False)\n",
        "      self.identity_conv.trainable=False\n",
        "      self.dx_conv = Conv4D(1, (3,3,3,3), bias=False)\n",
        "      self.dx_conv.trainable = False\n",
        "      self.dy_conv = Conv4D(1, (3,3,3,3), bias=False)\n",
        "      self.dx_conv.trainable = False\n",
        "      self.dz_conv = Conv4D(1, (3,3,3,3), bias=False)\n",
        "      self.dx_conv.trainable = False\n",
        "      self.da_conv = Conv4D(1, (3,3,3,3), bias=False)\n",
        "      self.dx_conv.trainable = False\n",
        "\n",
        "      self.dmodel = tf.keras.Sequential([\n",
        "            Conv4D(layers, (1, 1, 1, 1), activation=tf.nn.relu, padding='SAME'),\n",
        "            Conv4D(self.channel_n, (1, 1, 1, 1), activation=None,\n",
        "                kernel_initializer=tf.zeros_initializer),\n",
        "      ])\n",
        "\n",
        "      self(tf.zeros([8, 7, 7, 7, 7, channel_n]))  # dummy call to build the model\n",
        "\n",
        "\n",
        "  @tf.function\n",
        "  def perceive(self, x, angle=0.0):\n",
        "    identify = np.float32([[[0,0,0],[0,0,0],[0,0,0]],\n",
        "                          [[0,0,0],[0,1,0],[0,0,0]],\n",
        "                          [[0,0,0],[0,0,0],[0,0,0]]])\n",
        "    \n",
        "    if self.dim == 4:\n",
        "      identify = np.float32([[[[0,0,0],[0,0,0],[0,0,0]], [[0,0,0],[0,0,0],[0,0,0]], [[0,0,0],[0,0,0],[0,0,0]]],\n",
        "                            [[[0,0,0],[0,0,0],[0,0,0]], [[0,0,0],[0,1,0],[0,0,0]], [[0,0,0],[0,0,0],[0,0,0]]],\n",
        "                            [[[0,0,0],[0,0,0],[0,0,0]], [[0,0,0],[0,0,0],[0,0,0]], [[0,0,0],[0,0,0],[0,0,0]]]])\n",
        "      self.identity_conv.kernel = tf.reshape(identify, [3, 3, 3, 3, 1, 1])\n",
        "      \n",
        "    #3 dimensional sobel filter\n",
        "    dx = np.float32([[[-1,-2,-1],[0,0,0],[1,2,1]],\n",
        "                    [[-2,-4,-2],[0,0,0],[2,4,2]],\n",
        "                    [[-1,-2,-1],[0,0,0],[1,2,1]]]) \n",
        "    #4 dimensional sobel filter\n",
        "    if self.dim == 4:\n",
        "      temp = np.zeros(shape=(3, 3, 3, 3))\n",
        "      for d in range(3):\n",
        "        for i, j, k in itertools.product(range(3), range(3), range(3)):\n",
        "          temp[:, i, j, k] = dx[i, j, k] * np.array([1, 2, 1])\n",
        "      dx = temp.astype('float32')\n",
        "      self.dx_conv.kernel = tf.reshape(dx, [3, 3, 3, 3, 1, 1]) / 8.0\n",
        "    \n",
        "    dx /= 8.0  # Sobel filter\n",
        "\n",
        "    dy = np.float32([[[-1,-2,-1],[-2,-4,-2],[-1,-2,-1]],\n",
        "                    [[0,0,0],[0,0,0],[0,0,0]],\n",
        "                    [[1,2,1],[2,4,2],[1,2,1]]]) \n",
        "\n",
        "    if self.dim == 4:\n",
        "      temp = np.zeros(shape=(3, 3, 3, 3))\n",
        "      for d in range(3):\n",
        "        for i, j, k in itertools.product(range(3), range(3), range(3)):\n",
        "          temp[:, i, j, k] = dy[i, j, k] * np.array([1, 2, 1])\n",
        "      dy = temp.astype('float32')\n",
        "      self.dy_conv.kernel = tf.reshape(dy, [3, 3, 3, 3, 1, 1]) / 8.0\n",
        "    \n",
        "    dy /= 8.0\n",
        "\n",
        "    dz = np.float32([[[-1,0,1],[-2,0,2],[-1,0,1]],\n",
        "                    [[-2,0,2],[-4,0,4],[-2,0,2]],\n",
        "                    [[-1,0,1],[-1,0,1],[-1,0,1]]]) \n",
        "    \n",
        "    if self.dim == 4:\n",
        "      temp = np.zeros(shape=(3, 3, 3, 3))\n",
        "      for d in range(3):\n",
        "        for i, j, k in itertools.product(range(3), range(3), range(3)):\n",
        "          temp[:, i, j, k] = dz[i, j, k] * np.array([1, 2, 1])\n",
        "      dz = temp.astype('float32')\n",
        "      self.dz_conv.kernel = tf.reshape(dz, [3, 3, 3, 3, 1, 1]) / 8.0\n",
        "\n",
        "    dz /= 8.0\n",
        "\n",
        "    if self.dim == 4:\n",
        "      da = np.transpose(dx, axes=[2, 3, 0, 1]).astype('float32')\n",
        "      self.da_conv.kernel = tf.reshape(da, [3, 3, 3, 3, 1, 1])\n",
        "\n",
        "    #c, s, z = tf.cos(angle), tf.sin(angle), 0 #assume no rotation now\n",
        "    if self.dim == 3:\n",
        "      kernel = tf.stack([identify, dx, dy, dz], -1)[:, :, :, None, :]\n",
        "    #if self.dim == 4:\n",
        "    #  kernel = tf.stack([identify, dx, dy, dz, da], -1)[:, :, :, :, None, :]\n",
        "    \n",
        "    if self.dim == 3:\n",
        "      kernel = tf.repeat(kernel, self.channel_n, 2)\n",
        "      inputs = tf.unstack(x, axis = -1)\n",
        "      filters = tf.unstack(kernel, axis = -1)\n",
        "\n",
        "      y = tf.concat([tf.nn.conv3d(tf.expand_dims(i, axis = -1),\n",
        "                                  tf.expand_dims(f, axis = -1),\n",
        "                                  strides=[1,1,1,1,1], padding='SAME')\n",
        "                      for i, f in zip(inputs, filters)], axis = -1)\n",
        "    if self.dim == 4:\n",
        "      batch, a, b, c, d, chan = x.shape\n",
        "      x = tf.reshape(x, [batch * chan, a, b, c, d, 1])\n",
        "      id_out = tf.reshape(self.identity_conv(x), [batch, a, b, c, d, chan])\n",
        "      dx_out = tf.reshape(self.dx_conv(x), [batch, a, b, c, d, chan])\n",
        "      dy_out = tf.reshape(self.dy_conv(x), [batch, a, b, c, d, chan])\n",
        "      dz_out = tf.reshape(self.dz_conv(x), [batch, a, b, c, d, chan])\n",
        "      da_out = tf.reshape(self.da_conv(x), [batch, a, b, c, d, chan])\n",
        "\n",
        "      y = tf.concat([id_out, dx_out, dy_out, dz_out, da_out], axis = -1)\n",
        "    return y\n",
        "\n",
        "  @tf.function\n",
        "  def call(self, x, fire_rate=None, angle=0.0, step_size=1.0):\n",
        "    if self.dim == 3:\n",
        "      pre_life_mask = get_living_mask(x)\n",
        "    if self.dim == 4:\n",
        "      alpha = x[:, :, :, :, :, 1:2]\n",
        "      pre_life_mask = maxpool4d(alpha) > 0.1\n",
        "\n",
        "    y = self.perceive(x, angle)\n",
        "    dx = self.dmodel(y)*step_size\n",
        "    if fire_rate is None:\n",
        "      fire_rate = self.fire_rate\n",
        "    if self.dim == 3:\n",
        "      update_mask = tf.random.uniform(tf.shape(x[:, :, :, :, :1])) <= fire_rate\n",
        "    if self.dim == 4:\n",
        "      update_mask = tf.random.uniform(tf.shape(x[:, :, :, :, :, :1])) <= fire_rate\n",
        "  \n",
        "    x += dx * tf.cast(update_mask, tf.float32)\n",
        "\n",
        "    if self.dim == 3:\n",
        "      post_life_mask = get_living_mask(x)\n",
        "    if self.dim == 4:\n",
        "      alpha = x[:, :, :, :, :, 1:2]\n",
        "      post_life_mask = maxpool4d(alpha) > 0.1\n",
        "\n",
        "    life_mask = pre_life_mask & post_life_mask\n",
        "    return x * tf.cast(life_mask, tf.float32)\n",
        "\n",
        "\n",
        "CAModel().dmodel.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyQEcMhhJt_K"
      },
      "source": [
        "from google.protobuf.json_format import MessageToDict\n",
        "from tensorflow.python.framework import convert_to_constants\n",
        "\n",
        "\n",
        "class SamplePool:\n",
        "  def __init__(self, *, _parent=None, _parent_idx=None, **slots):\n",
        "    self._parent = _parent\n",
        "    self._parent_idx = _parent_idx\n",
        "    self._slot_names = slots.keys()\n",
        "    self._size = None\n",
        "    for k, v in slots.items():\n",
        "      if self._size is None:\n",
        "        self._size = len(v)\n",
        "      assert self._size == len(v)\n",
        "      setattr(self, k, np.asarray(v))\n",
        "\n",
        "  def sample(self, n):\n",
        "    idx = np.random.choice(self._size, n, False)\n",
        "    batch = {k: getattr(self, k)[idx] for k in self._slot_names}\n",
        "    batch = SamplePool(**batch, _parent=self, _parent_idx=idx)\n",
        "    return batch\n",
        "\n",
        "  def commit(self):\n",
        "    for k in self._slot_names:\n",
        "      getattr(self._parent, k)[self._parent_idx] = getattr(self, k)\n",
        "\n",
        "def export_model(ca, base_fn, loss):\n",
        "  ca.save_weights(base_fn)\n",
        "  np.save('temporal_loss.npy', loss)\n",
        "\n",
        "def plot_loss(loss_log):\n",
        "  pl.figure(figsize=(10, 4))\n",
        "  pl.title('Loss history')\n",
        "  pl.plot(np.log10(loss_log), '.', alpha=1.0)\n",
        "  pl.show()"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni7nxsuheCSP"
      },
      "source": [
        "#save sequence\n",
        "np.save('temporal_seq.npy', seq)"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilAdPTXKE_VL"
      },
      "source": [
        "pad_target = tf.convert_to_tensor(seq, dtype=tf.float32)\n",
        "a, h, w, d = pad_target.shape[:4]\n",
        "seed = np.zeros([a, h, w, d, CHANNEL_N], np.float32)\n",
        "seed[a//2, h//2, w//2, d//2, 1:] = 1.0\n",
        "\n",
        "def loss_f(x):\n",
        "  return tf.math.reduce_mean(tf.square(x[..., 0:2]-pad_target), [-2, -3, -4, -5, -1])\n",
        "\n",
        "ca = CAModel(dim=4, layers=128)\n",
        "\n",
        "loss_log = []\n",
        "\n",
        "lr = 2e-4\n",
        "lr_sched = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    [2000, 5000], [lr, lr*0.1, lr*0.01])\n",
        "trainer = tf.keras.optimizers.Adam(lr_sched)\n",
        "\n",
        "loss0 = loss_f(seed).numpy()\n",
        "pool = SamplePool(x=np.repeat(seed[None, ...], POOL_SIZE, 0))"
      ],
      "execution_count": 306,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQnunQ5TPCnv"
      },
      "source": [
        "@tf.function\n",
        "def train_step(x):\n",
        "  iter_n = tf.random.uniform([], 32, 64, tf.int32)\n",
        "  with tf.GradientTape() as g:\n",
        "    for i in tf.range(iter_n):\n",
        "      x = ca(x)\n",
        "    loss = tf.reduce_mean(loss_f(x))\n",
        "  grads = g.gradient(loss, ca.weights)\n",
        "  grads = [g/(tf.norm(g)+1e-8) for g in grads]\n",
        "  trainer.apply_gradients(zip(grads, ca.weights))\n",
        "  return x, loss\n",
        "\n",
        "while len(loss_log) < 10001:\n",
        "  if USE_PATTERN_POOL:\n",
        "    batch = pool.sample(BATCH_SIZE)\n",
        "    x0 = batch.x\n",
        "    loss_rank = loss_f(x0).numpy().argsort()[::-1]\n",
        "    x0 = x0[loss_rank]\n",
        "    x0[:1] = seed\n",
        "  else:\n",
        "    x0 = np.repeat(seed[None, ...], BATCH_SIZE, 0)\n",
        "\n",
        "  x, loss = train_step(x0)\n",
        "\n",
        "  if USE_PATTERN_POOL:\n",
        "    batch.x[:] = x\n",
        "    batch.commit()\n",
        "\n",
        "  step_i = len(loss_log)\n",
        "  loss_log.append(loss.numpy())\n",
        "\n",
        "  if step_i%100 == 0:\n",
        "    clear_output()\n",
        "    plot_loss(loss_log)\n",
        "    export_model(ca, '%04d'%step_i, loss_log)\n",
        "  \n",
        "  print('\\r step: %d, log loss: %f'%(len(loss_log), np.log10(loss)), end='')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3JWWJAVCe-Q"
      },
      "source": [
        "#find the mse for the outputs\n",
        "for i in range(4):\n",
        "  generated = x[i, ...].numpy()\n",
        "  generated = generated[..., 0]\n",
        "  mse = (np.square(generated - seq[..., 0])).mean()\n",
        "  print(mse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx-MRlKx-dtR"
      },
      "source": [
        "generated = x[0, ...].numpy()\n",
        "generated = generated[..., 0]"
      ],
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnyWk8I9-MSt"
      },
      "source": [
        "#visualize outputs\n",
        "\n",
        "X, Y, Z = np.mgrid[0:5:1, 0:5:1, 0:5:1]\n",
        "\n",
        "fig = go.Figure(data=go.Volume(\n",
        "    x=X.flatten(),\n",
        "    y=Y.flatten(),\n",
        "    z=Z.flatten(),\n",
        "    value=generated[0, ...].flatten(),\n",
        "    isomin=0.1,\n",
        "    isomax=1.0,\n",
        "    opacity=1.0, \n",
        "    surface_count=600, \n",
        "    ))\n",
        "#fig.write_image(\"teporal_generated_first.png\")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}